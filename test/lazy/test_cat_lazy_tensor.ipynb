{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.lazy import CatLazyTensor, NonLazyTensor\n",
    "import torch, gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-batched cat dim 0 pass\n",
    "x = NonLazyTensor(torch.randn(5,1))\n",
    "y = NonLazyTensor(torch.randn(4,1))\n",
    "\n",
    "z = CatLazyTensor(*[x,y], dim=0)\n",
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-batched cat dim 1 pass\n",
    "x = NonLazyTensor(torch.randn(4,3))\n",
    "y = NonLazyTensor(torch.randn(4,2))\n",
    "\n",
    "#%debug\n",
    "z = CatLazyTensor(*[x,y], dim=1)\n",
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/alex/ml/repos/gpytorch/gpytorch/lazy/lazy_tensor.py(603)evaluate()\n",
      "-> num_rows, num_cols = self.matrix_shape\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0054,  0.1399,  1.4804, -0.0780, -0.0651],\n",
       "        [ 0.8638,  1.5334, -0.7149, -1.0489,  0.6530],\n",
       "        [-0.6671,  0.0170, -1.5074,  0.1772, -0.5618],\n",
       "        [-0.6395, -0.7474, -0.0772,  0.0416,  0.8329]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "All LazyTensors must have the same size in the non-concatenation dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3342269c7acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNonLazyTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatLazyTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ml/repos/gpytorch/gpytorch/lazy/cat_lazy_tensor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dim, output_device, *lazy_tensors)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All tensors must have the same number of dimensions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremove_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mremove_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 raise RuntimeError(\"All LazyTensors must have the same size in \"\n\u001b[0m\u001b[1;32m     53\u001b[0m                                    \"the non-concatenation dimension\")\n\u001b[1;32m     54\u001b[0m             \u001b[0mtensor_idx_to_start_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_dim_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: All LazyTensors must have the same size in the non-concatenation dimension"
     ]
    }
   ],
   "source": [
    "# Non-batched cat dim 0 fail\n",
    "x = NonLazyTensor(torch.randn(5,3))\n",
    "y = NonLazyTensor(torch.randn(4,2))\n",
    "\n",
    "z = CatLazyTensor(*[x,y], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-batched cat dim 1 fail\n",
    "x = NonLazyTensor(torch.randn(5,3))\n",
    "y = NonLazyTensor(torch.randn(4,2))\n",
    "z = CatLazyTensor(*[x,y], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batched cat dim 0 pass\n",
    "x = NonLazyTensor(torch.randn(3,4,1))\n",
    "y = NonLazyTensor(torch.randn(1,4,1))\n",
    "\n",
    "#%debug\n",
    "z = CatLazyTensor(*[x,y], dim=0)\n",
    "print(z.size())\n",
    "z.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batched cat dim 1 pass\n",
    "x = NonLazyTensor(torch.randn(1,5,1))\n",
    "y = NonLazyTensor(torch.randn(1,4,1))\n",
    "\n",
    "#%debug\n",
    "z = CatLazyTensor(*[x,y], dim=1)\n",
    "print(z.size())\n",
    "z.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batched cat dim 2 pass\n",
    "x = NonLazyTensor(torch.randn(2,4,3))\n",
    "y = NonLazyTensor(torch.randn(2,4,2))\n",
    "z = CatLazyTensor(*[x,y], dim=2)\n",
    "print(z.size())\n",
    "z.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batched cat dim 1 fail\n",
    "x = NonLazyTensor(torch.randn(1, 5,3))\n",
    "y = NonLazyTensor(torch.randn(1, 4,2))\n",
    "z = CatLazyTensor(*[x,y], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batched cat dim 2 fail\n",
    "x = NonLazyTensor(torch.randn(2, 5,3))\n",
    "y = NonLazyTensor(torch.randn(2, 4,2))\n",
    "\n",
    "z = CatLazyTensor(*[x,y], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _matmul non-batched against 1D, dim=0\n",
    "x = NonLazyTensor(torch.randn(5,2))\n",
    "y = NonLazyTensor(torch.randn(4,2))\n",
    "z = CatLazyTensor(*[x,y], dim=0)\n",
    "\n",
    "b = torch.randn(2)\n",
    "\n",
    "print(z.matmul(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _matmul non-batched against 2D , dim=0\n",
    "x = NonLazyTensor(torch.randn(5,2))\n",
    "y = NonLazyTensor(torch.randn(4,2))\n",
    "z = CatLazyTensor(*[x,y], dim=0)\n",
    "\n",
    "b = torch.randn(2,3)\n",
    "\n",
    "z.matmul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _matmul batched against 1D, dim=1\n",
    "x = NonLazyTensor(torch.randn(3,5,2))\n",
    "y = NonLazyTensor(torch.randn(3,4,2))\n",
    "z = CatLazyTensor(*[x,y], dim=1)\n",
    "\n",
    "b = torch.randn(2)\n",
    "\n",
    "z.matmul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _matmul batched against 2D, dim=0\n",
    "x = NonLazyTensor(torch.randn(3,5,2))\n",
    "y = NonLazyTensor(torch.randn(3,4,2))\n",
    "z = CatLazyTensor(*[x,y], dim=1)\n",
    "\n",
    "b = torch.randn(2,6)\n",
    "\n",
    "z.matmul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _matmul non-batched against 1D, dim=1\n",
    "x = NonLazyTensor(torch.randn(3,2))\n",
    "y = NonLazyTensor(torch.randn(3,5))\n",
    "z = CatLazyTensor(*[x,y], dim=1)\n",
    "\n",
    "b = torch.randn(7)\n",
    "\n",
    "z.matmul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _matmul non-batched against 2D , dim=1\n",
    "x = NonLazyTensor(torch.randn(7,3))\n",
    "y = NonLazyTensor(torch.randn(7,2))\n",
    "z = CatLazyTensor(*[x,y], dim=1)\n",
    "\n",
    "b = torch.randn(5,3)\n",
    "\n",
    "z.matmul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _matmul batched against 1D, dim=1\n",
    "x = NonLazyTensor(torch.randn(3,4,8))\n",
    "y = NonLazyTensor(torch.randn(3,4,2))\n",
    "z = CatLazyTensor(*[x,y], dim=2)\n",
    "\n",
    "b = torch.randn(10)\n",
    "\n",
    "z.matmul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _matmul batched against 2D, dim=1\n",
    "x = NonLazyTensor(torch.randn(3,4,10))\n",
    "y = NonLazyTensor(torch.randn(3,4,2))\n",
    "z = CatLazyTensor(*[x,y], dim=2)\n",
    "\n",
    "b = torch.randn(12,1)\n",
    "\n",
    "z.matmul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matmul batched against 3D, dim=2\n",
    "x = NonLazyTensor(torch.randn(3,4,10))\n",
    "y = NonLazyTensor(torch.randn(3,4,2))\n",
    "z = CatLazyTensor(*[x,y], dim=2)\n",
    "\n",
    "b = torch.randn(3,12,1)\n",
    "\n",
    "z.matmul(b).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matmul batched against 3D, dim=1\n",
    "x = NonLazyTensor(torch.randn(3,7,2))\n",
    "y = NonLazyTensor(torch.randn(3,4,2))\n",
    "z = CatLazyTensor(*[x,y], dim=1)\n",
    "\n",
    "b = torch.randn(3,2,1)\n",
    "print(z.size())\n",
    "z.matmul(b).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matmul batched against 3D, dim=0\n",
    "x = NonLazyTensor(torch.randn(5,4,2))\n",
    "y = NonLazyTensor(torch.randn(3,4,2))\n",
    "z = CatLazyTensor(*[x,y], dim=0)\n",
    "\n",
    "b = torch.randn(8,2,1)\n",
    "print(z.size())\n",
    "z.matmul(b).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose\n",
    "x = NonLazyTensor(torch.randn(3,4,10))\n",
    "y = NonLazyTensor(torch.randn(3,4,2))\n",
    "\n",
    "print(z.size(), z.transpose(1, 2).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatLazyTensor of CatLazyTensors\n",
    "x = NonLazyTensor(torch.randn(5,1))\n",
    "y = NonLazyTensor(torch.randn(4,1))\n",
    "z = CatLazyTensor(*[x,y], dim=0)\n",
    "\n",
    "zz = CatLazyTensor(*[z,z], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Slice a CatLazyTensor\n",
    "x = NonLazyTensor(torch.randn(5,2))\n",
    "y = NonLazyTensor(torch.randn(4,2))\n",
    "z = CatLazyTensor(*[x,y], dim=0)\n",
    "\n",
    "zz = CatLazyTensor(*[z,z], dim=1)\n",
    "print(torch.equal(zz.evaluate()[:, 1::2], zz[:, 1::2].evaluate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Slice a CatLazyTensor\n",
    "w = NonLazyTensor(torch.randn(3,2))\n",
    "x = NonLazyTensor(torch.randn(3,2))\n",
    "y = NonLazyTensor(torch.randn(4,2))\n",
    "z = CatLazyTensor(*[w,x,y], dim=0)\n",
    "\n",
    "indices = (torch.tensor([1,0,9,3,8,5]), torch.tensor([1,0,1,1,0,0]))\n",
    "print(z.evaluate()[indices])\n",
    "print(z[indices].evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice a CatLazyTensor\n",
    "x = NonLazyTensor(torch.randn(1, 5, 2))\n",
    "y = NonLazyTensor(torch.randn(1, 4, 2))\n",
    "z = CatLazyTensor(*[x,y], dim=1)\n",
    "\n",
    "#zz = CatLazyTensor(*[z,z], dim=2)\n",
    "zz = z\n",
    "indices = (0, torch.tensor([0,1]), torch.tensor([0,1]))\n",
    "exp = zz.evaluate()[indices]\n",
    "act = zz[indices]\n",
    "print(exp)\n",
    "print(act.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/alex/ml/repos/gpytorch/gpytorch/lazy/cat_lazy_tensor.py(104)_getitem()\n",
      "-> squeeze = [isinstance(i, int) for i in indices]\n",
      "(Pdb) c\n",
      "> /home/alex/ml/repos/gpytorch/gpytorch/lazy/cat_lazy_tensor.py(104)_getitem()\n",
      "-> squeeze = [isinstance(i, int) for i in indices]\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gpytorch.lazy.cat_lazy_tensor.CatLazyTensor at 0x7f14668b9908>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice a CatLazyTensor\n",
    "x = NonLazyTensor(torch.randn(1, 5, 2))\n",
    "y = NonLazyTensor(torch.randn(1, 4, 2))\n",
    "z = CatLazyTensor(*[x,y], dim=1)\n",
    "\n",
    "zz = CatLazyTensor(*[z,z], dim=2)\n",
    "\n",
    "indices = (0, torch.tensor([0,1]), torch.tensor([0,1]))\n",
    "zz[indices]\n",
    "#print(zz[indices].evaluate())\n",
    "#print(zz.evaluate()[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/alex/ml/repos/gpytorch/gpytorch/lazy/cat_lazy_tensor.py(104)_getitem()\n",
      "-> squeeze = [isinstance(i, int) for i in indices]\n",
      "(Pdb) c\n",
      "> /home/alex/ml/repos/gpytorch/gpytorch/lazy/cat_lazy_tensor.py(104)_getitem()\n",
      "-> squeeze = [isinstance(i, int) for i in indices]\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz[indices].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[(slice(0, 1, None), torch.tensor([0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[(0, torch.tensor([0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = CatLazyTensor(*[NonLazyTensor(torch.randn(3,2))], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/alex/ml/repos/gpytorch/gpytorch/lazy/lazy_tensor.py(603)evaluate()\n",
      "-> num_rows, num_cols = self.matrix_shape\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.9705, -0.0777,  0.8107])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.matmul(NonLazyTensor(torch.randn(2))).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
